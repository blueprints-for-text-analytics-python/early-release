{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Remark<div class='tocSkip'/>\n",
    "\n",
    "The code in this notebook differs slightly from the printed book. For example we frequently use pretty print (`pp.pprint`) instead of `print` and `tqdm`'s `progress_apply` instead of Pandas' `apply`. \n",
    "\n",
    "Moreover, several layout and formatting commands, like `figsize` to control figure size or subplot commands are removed in the book.\n",
    "\n",
    "You may also find some lines marked with three hashes ###. Those are not in the book as well as they don't contribute to the concept.\n",
    "\n",
    "All of this is done to simplify the code in the book and put the focus on the important parts instead of formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3UVlFeb3-j1",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Setup<div class='tocSkip'/>\n",
    "\n",
    "## Determine Environment<div class='tocSkip'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:49.762540Z",
     "start_time": "2020-06-24T20:33:49.755662Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z5CvQu904xx4",
    "outputId": "445c085e-16ea-4515-c059-1cb9edc3f374",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    BASE_DIR = \"/content\"\n",
    "    print(\"You are working on Google Colab.\")\n",
    "    print(f'Files will be downloaded to \"{BASE_DIR}\".')\n",
    "    # adjust release\n",
    "    GIT_ROOT = \"https://github.com/blueprints-for-text-analytics-python/early-release/raw/master\"\n",
    "else:\n",
    "    BASE_DIR = \"../\"\n",
    "    print(\"You are working on a local system.\")\n",
    "    print(f'Files will be searched relative to \"{BASE_DIR}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Download files on Google Colab<div class='tocSkip'/>\n",
    "\n",
    "If you are on Colab, copy the following statements into the code cell below and execute them.\n",
    "\n",
    "```bash\n",
    "!wget -P $BASE_DIR $GIT_ROOT/settings.py\n",
    "\n",
    "!mkdir -p $BASE_DIR/data/un-general-debates\n",
    "\n",
    "!wget -P $BASE_DIR/data/un-general-debates $GIT_ROOT/data/un-general-debates/un-general-debates-blueprint.csv.gz \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XR2aPCyiCAJL",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Install required libraries<div class='tocSkip'/>\n",
    "\n",
    "Still todo: setup pip requirements.txt\n",
    "\n",
    "If you are on Colab, copy the following statements into the code cell below and execute them.\n",
    "\n",
    "```bash\n",
    "!pip install textacy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "colab_type": "code",
    "id": "f820vBIQd5EB",
    "outputId": "7686da1c-0c34-43ed-cf4a-abd3c8f29316",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:50.988791Z",
     "start_time": "2020-06-24T20:33:49.770949Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# make sure stop words are available\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Load Python Settings<div class=\"tocSkip\"/>\n",
    "\n",
    "Common imports, defaults for formatting in Matplotlib, Pandas etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:52.240329Z",
     "start_time": "2020-06-24T20:33:50.992009Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "%run \"$BASE_DIR/settings.py\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to gain first Insights from Textual Data\n",
    "## What you will learn and what we will build\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T15:39:13.555307Z",
     "start_time": "2019-08-12T15:39:13.154307Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducing the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:57.691068Z",
     "start_time": "2020-06-24T20:33:52.244696Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 150 ###\n",
    "file = f\"{BASE_DIR}/data/un-general-debates/un-general-debates-blueprint.csv.gz\"\n",
    "df = pd.read_csv(file)\n",
    "df.sample(2, random_state=53)\n",
    "### Table tab-data-sample: Sample of the UN General Debates Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Blueprint: Getting an Overview of the Data with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T19:46:18.074107Z",
     "start_time": "2019-12-09T19:46:17.946114Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculating Summary Statistics for Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:57.767669Z",
     "start_time": "2020-06-24T20:33:57.695311Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['length'] = df['text'].str.len()\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:57.850501Z",
     "start_time": "2020-06-24T20:33:57.770813Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df[['country', 'speaker']].describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Checking for Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:57.892393Z",
     "start_time": "2020-06-24T20:33:57.853297Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:57.945190Z",
     "start_time": "2020-06-24T20:33:57.895814Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['speaker'].fillna('unkown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:58.000020Z",
     "start_time": "2020-06-24T20:33:57.950961Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df[df['speaker'].str.contains('Bush')]['speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting Value Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:58.522440Z",
     "start_time": "2020-06-24T20:33:58.003926Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['length'].plot(kind='box', vert=False, figsize=(8, 1))\n",
    "### img_width: 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:58.969214Z",
     "start_time": "2020-06-24T20:33:58.530307Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['length'].plot(kind='hist', bins=30, figsize=(8,2))\n",
    "### img_width: 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:33:59.461095Z",
     "start_time": "2020-06-24T20:33:58.973184Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# with gaussian kernel density estimate in seaborn\n",
    "plt.figure(figsize=(8, 2))\n",
    "sns.distplot(df['length'], bins=30, kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing Value Distributions across Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:00.821644Z",
     "start_time": "2020-06-24T20:33:59.464671Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(8, 3)) ###\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.4, hspace=None) ###\n",
    "\n",
    "where = df['country'].isin(['USA', 'FRA', 'GBR', 'CHN', 'RUS'])\n",
    "sns.catplot(data=df[where], x=\"country\", y=\"length\", kind='box', ax=axes[0])\n",
    "sns.catplot(data=df[where], x=\"country\", y=\"length\", kind='violin', ax=axes[1])\n",
    "\n",
    "#plt.close(2)### empty subplot\n",
    "#plt.close(3)### empty subplot\n",
    "### Figure fig-box-violin: Box plots (left) and violin plots (right) visualizing the distribution of speech lengths for selected countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing Developments over Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:01.225774Z",
     "start_time": "2020-06-24T20:34:00.824077Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('year').size().plot(title=\"Number of Countries\", figsize=(6,2))\n",
    "### img_width: 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:01.595202Z",
     "start_time": "2020-06-24T20:34:01.228965Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('year').agg({'length': 'mean'}) \\\n",
    "  .plot(title=\"Avg. Speech Length\", ylim=(0,30000), figsize=(6,2))\n",
    "### img_width: 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:02.343444Z",
     "start_time": "2020-06-24T20:34:01.602168Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(10, 2)) ###\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.4, hspace=None) ###\n",
    "\n",
    "df.groupby('year').size().plot(title=\"Number of Countries\", ax=axes[0])\n",
    "df.groupby('year').agg({'length': 'mean'}).plot(title=\"Avg. Speech Length\", ax=axes[1], ylim=(0,30000))\n",
    "\n",
    "plt.close(2)### empty subplot\n",
    "plt.close(3)### empty subplot\n",
    "### Figure fig-timeline: Number of countries and average speech length over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Blueprint: Building a Simple Text Preprocessing Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenization with Regular Expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:02.380684Z",
     "start_time": "2020-06-24T20:34:02.347877Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:02.426835Z",
     "start_time": "2020-06-24T20:34:02.386378Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Let's defeat SARS-CoV-2 together in 2020!\"\n",
    "tokens = tokenize(text)\n",
    "print(\"|\".join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Treating Stop Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:02.471638Z",
     "start_time": "2020-06-24T20:34:02.430451Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    return [t for t in tokens if t.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:02.524392Z",
     "start_time": "2020-06-24T20:34:02.474589Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "include_stopwords = {'dear', 'regards', 'must', 'would', 'also'}\n",
    "exclude_stopwords = {'against'}\n",
    "\n",
    "stopwords |= include_stopwords\n",
    "stopwords -= exclude_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Processing a Pipeline with one Line of Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:02.564303Z",
     "start_time": "2020-06-24T20:34:02.527464Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = [str.lower, tokenize, remove_stop]\n",
    "\n",
    "def prepare(text, pipeline):\n",
    "    tokens = text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:24.403809Z",
     "start_time": "2020-06-24T20:34:02.569278Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].progress_apply(prepare, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:24.503450Z",
     "start_time": "2020-06-24T20:34:24.407416Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['no_tokens'] = df['tokens'].progress_map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analyzing Word Frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Blueprint: Counting Words with a Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:24.552186Z",
     "start_time": "2020-06-24T20:34:24.510780Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokens = tokenize(\"She likes my cats and my cats like my sofa.\")\n",
    "\n",
    "counter = Counter(tokens)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:24.583605Z",
     "start_time": "2020-06-24T20:34:24.555580Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "more_tokens = tokenize(\"She likes dogs and cats.\")\n",
    "counter.update(more_tokens)\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:27.042582Z",
     "start_time": "2020-06-24T20:34:24.587283Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "\n",
    "### progress map does not work with counter.update\n",
    "_ = df['tokens'].map(counter.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:27.099017Z",
     "start_time": "2020-06-24T20:34:27.045762Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pp.pprint(counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:27.134136Z",
     "start_time": "2020-06-24T20:34:27.101498Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter ###\n",
    "def count_words(df, column='tokens', preprocess=None, min_freq=2):\n",
    "\n",
    "    # process tokens and update counter\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # create counter and run through all data\n",
    "    counter = Counter()\n",
    "    df[column].progress_map(update)\n",
    "\n",
    "    # transform counter into data frame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    \n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:29.260762Z",
     "start_time": "2020-06-24T20:34:27.137549Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "freq_df = count_words(df)\n",
    "freq_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T20:10:12.989692Z",
     "start_time": "2019-12-23T20:10:12.806693Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Blueprint: Creating a Frequency Diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:29.660390Z",
     "start_time": "2020-06-24T20:34:29.264181Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### img_width: 80%\n",
    "ax = freq_df.head(15).plot(kind='barh', width=0.95, figsize=(8,3))\n",
    "ax.invert_yaxis()\n",
    "ax.set(xlabel='Frequency', ylabel='Token', title='Top Words')\n",
    "### ax.legend(['Frequencies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Blueprint: Creating Word Clouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:30.284442Z",
     "start_time": "2020-06-24T20:34:29.663379Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "text = df.query(\"year==2015 and country=='USA'\")['text'].values[0]\n",
    "\n",
    "plt.figure(figsize=(2,1)) ###\n",
    "wc = WordCloud(max_words=100, stopwords=stopwords)\n",
    "wc.generate(text)\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "### img_width: 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:30.377974Z",
     "start_time": "2020-06-24T20:34:30.292265Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud ###\n",
    "from collections import Counter ###\n",
    "\n",
    "def wordcloud(word_freq, title=None, max_words=200, stopwords=None):\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, \n",
    "                   background_color= \"black\", colormap=\"Paired\", \n",
    "                   max_font_size=150, max_words=max_words)\n",
    "    \n",
    "    # convert data frame into dict\n",
    "    if type(word_freq) == pd.Series:\n",
    "        counter = Counter(word_freq.fillna(0).to_dict())\n",
    "    else:\n",
    "        counter = word_frequencies\n",
    "\n",
    "    # filter stop words in frequency counter\n",
    "    if stopwords is not None:\n",
    "        counter = {token:freq for (token, freq) in counter.items() \n",
    "                              if token not in stopwords}\n",
    "    wc.generate_from_frequencies(counter)\n",
    " \n",
    "    plt.title(title) \n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:32.576823Z",
     "start_time": "2020-06-24T20:34:30.380786Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "freq_2015_df = count_words(df[df['year']==2015])\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)###\n",
    "wordcloud(freq_2015_df['freq'], max_words=100)\n",
    "plt.subplot(1,2,2)###\n",
    "wordcloud(freq_2015_df['freq'], max_words=100, stopwords=freq_df.head(50).index)\n",
    "#plt.tight_layout()###\n",
    "### img_width: 100%\n",
    "### Figure fig-2015-speeches: Word clouds for the 2015 speeches including all words (left) and without the 50 most frequent words (right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Blueprint: Ranking with TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:32.642508Z",
     "start_time": "2020-06-24T20:34:32.583663Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def idf(df, column='tokens', preprocess=None, min_df=2):\n",
    "\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(set(tokens))\n",
    "\n",
    "    # count tokens\n",
    "    counter = Counter()\n",
    "    df[column].progress_map(update)\n",
    "\n",
    "    # create data frame and compute idf\n",
    "    idf_df = pd.DataFrame.from_dict(counter, orient='index', columns=['df'])\n",
    "    idf_df = idf_df[idf_df['df'] >= min_df]\n",
    "    idf_df['idf'] = np.log(len(df)/idf_df['df'])+0.1\n",
    "    idf_df.index.name = 'token'\n",
    "    return idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:35.603960Z",
     "start_time": "2020-06-24T20:34:32.645474Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "idf_df = idf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:35.698904Z",
     "start_time": "2020-06-24T20:34:35.606374Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### freq_df['tfidf'] = freq_df['freq'] * idf_df['idf'] # too slow\n",
    "freq_df = freq_df.join(idf_df)\n",
    "freq_df['tfidf'] = freq_df['freq'] * freq_df['idf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:40.397977Z",
     "start_time": "2020-06-24T20:34:35.701388Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "freq_1970 = count_words(df[df['year'] == 1970])\n",
    "freq_2015 = count_words(df[df['year'] == 2015])\n",
    "\n",
    "freq_1970['tfidf'] = freq_1970['freq'] * idf_df['idf']\n",
    "freq_2015['tfidf'] = freq_2015['freq'] * idf_df['idf']\n",
    "\n",
    "plt.figure(figsize=(12,6)) ###\n",
    "#wordcloud(freq_df['freq'], title='All years', subplot=(1,3,1))\n",
    "plt.subplot(2,2,1)###\n",
    "wordcloud(freq_1970['freq'], title='1970 - TF', \n",
    "          stopwords=['twenty-fifth', 'twenty-five'])\n",
    "plt.subplot(2,2,2)###\n",
    "wordcloud(freq_2015['freq'], title='2015 - TF', \n",
    "          stopwords=['seventieth'])\n",
    "plt.subplot(2,2,3)###\n",
    "wordcloud(freq_1970['tfidf'], title='1970 - TF-IDF', \n",
    "          stopwords=['twenty-fifth', 'twenty-five', 'twenty', 'fifth'])\n",
    "plt.subplot(2,2,4)###\n",
    "wordcloud(freq_2015['tfidf'], title='2015 - TF-IDF', \n",
    "          stopwords=['seventieth'])\n",
    "### Figure fig-tf-idf: Words weighted by plain counts (upper) and TF-IDF (lower) for speeches in two selected years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Blueprint: Finding a Keyword in Context (KWIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:40.764809Z",
     "start_time": "2020-06-24T20:34:40.401456Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from textacy.text_utils import KWIC\n",
    "\n",
    "def kwic(doc_series, keyword, window=35, print_samples=None):\n",
    "\n",
    "    def add_kwic(text):\n",
    "        kwic_list.extend(KWIC(text, keyword, ignore_case=True, \n",
    "                              window_width=window, print_only=False))\n",
    "\n",
    "    kwic_list = []\n",
    "    doc_series.progress_map(add_kwic)\n",
    "\n",
    "    if print_samples is None or print_samples==0:\n",
    "        return kwic_list\n",
    "    else:\n",
    "        k = min(print_samples, len(kwic_list))\n",
    "        print(f\"{k} random samples out of {len(kwic_list)} \" + \\\n",
    "              f\"contexts for '{keyword}':\")\n",
    "        for sample in random.sample(list(kwic_list), k):\n",
    "            print(re.sub(r'[\\n\\t]', ' ', sample[0])+'  '+ \\\n",
    "                  sample[1]+'  '+\\\n",
    "                  re.sub(r'[\\n\\t]', ' ', sample[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:40.889292Z",
     "start_time": "2020-06-24T20:34:40.767832Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(22) ###\n",
    "kwic(df[df['year'] == 2015]['text'], 'sdgs', window=35, print_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:40.920331Z",
     "start_time": "2020-06-24T20:34:40.892336Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from textacy.text_utils import KWIC\n",
    "\n",
    "def kwic(doc_series, keyword, window=35, print_samples=5):\n",
    "\n",
    "    def add_kwic(text):\n",
    "        kwic_list.extend(KWIC(text, keyword, ignore_case=True, \n",
    "                              window_width=window, print_only=False))\n",
    "\n",
    "    kwic_list = []\n",
    "    doc_series.progress_map(add_kwic)\n",
    "\n",
    "    if print_samples is None or print_samples==0:\n",
    "        return kwic_list\n",
    "    else:\n",
    "        k = min(print_samples, len(kwic_list))\n",
    "        print(f\"{k} random samples out of {len(kwic_list)} \" + \\\n",
    "              f\"contexts for '{keyword}':\")\n",
    "        for sample in random.sample(list(kwic_list), k):\n",
    "            print(re.sub(r'[\\n\\t]', ' ', sample[0])+'  '+ \\\n",
    "                  sample[1]+'  '+\\\n",
    "                  re.sub(r'[\\n\\t]', ' ', sample[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:41.036415Z",
     "start_time": "2020-06-24T20:34:40.922504Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(22) ###\n",
    "kwic(df[df['year'] == 2015]['text'], 'sdgs', print_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Blueprint: Analyzing N-Grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:41.071968Z",
     "start_time": "2020-06-24T20:34:41.039288Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \"the visible manifestation of the global climate change\"\n",
    "tokens = tokenize(text)\n",
    "\n",
    "def ngrams(tokens, n=2, sep=' '):\n",
    "    return [sep.join(ngram) for ngram in zip(*[tokens[i:] for i in range(n)])]\n",
    "\n",
    "print(\"|\".join(ngrams(tokens, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:34:41.110522Z",
     "start_time": "2020-06-24T20:34:41.074534Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def ngrams(tokens, n=2, sep=' ', stopwords=set()):\n",
    "    return [sep.join(ngram) for ngram in zip(*[tokens[i:] for i in range(n)])\n",
    "            if len([t for t in ngram if t in stopwords])==0]\n",
    "\n",
    "tokens = prepare(text, [str.lower, tokenize]) # keep full list of tokens\n",
    "\n",
    "print(\"Bigrams:\", \"|\".join(ngrams(tokens, 2, stopwords=stopwords)))\n",
    "print(\"Trigrams:\", \"|\".join(ngrams(tokens, 3, stopwords=stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:32.512156Z",
     "start_time": "2020-06-24T20:34:41.113319Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['bigrams'] = df['text'].progress_apply(prepare, pipeline=[str.lower, tokenize]) \\\n",
    "                          .progress_apply(ngrams, n=2, stopwords=stopwords)\n",
    "\n",
    "count_words(df, 'bigrams').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:40.795318Z",
     "start_time": "2020-06-24T20:35:32.516066Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "idf_df = idf(df) ### re-initialize to be safe\n",
    "# concatenate existing IDF data frame with bigram IDFs\n",
    "idf_df = pd.concat([idf_df, idf(df, 'bigrams', min_df=10)])\n",
    "\n",
    "freq_df = count_words(df[df['year'] == 2015], 'bigrams')\n",
    "freq_df['tfidf'] = freq_df['freq'] * idf_df['idf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:41.890805Z",
     "start_time": "2020-06-24T20:35:40.802117Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6)) ###\n",
    "plt.subplot(1,2,1) ###\n",
    "wordcloud(freq_df['tfidf'], title='all bigrams', max_words=50)\n",
    "\n",
    "plt.subplot(1,2,2) ###\n",
    "# plt.tight_layout() ###\n",
    "where = freq_df.index.str.contains('climate')\n",
    "wordcloud(freq_df[where]['freq'], title='\"climate\" bigrams', max_words=50)\n",
    "### Figure fig-bigrams: Word clouds for all bigrams and bigrams containing \"climate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Blueprint: Comparing Frequencies across Time-Intervals and Categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating Frequency Timelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:41.970369Z",
     "start_time": "2020-06-24T20:35:41.893378Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def count_keywords(tokens, keywords): \n",
    "    tokens = [t for t in tokens if t in keywords]\n",
    "    counter = Counter(tokens)\n",
    "    return [counter.get(k, 0) for k in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:42.025084Z",
     "start_time": "2020-06-24T20:35:41.973433Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keywords = ['nuclear', 'terrorism', 'climate', 'freedom']\n",
    "tokens = ['nuclear', 'climate', 'climate', 'freedom', 'climate', 'freedom']\n",
    "\n",
    "print(count_keywords(tokens, keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:42.062559Z",
     "start_time": "2020-06-24T20:35:42.030896Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def count_keywords_by(df, by, column='tokens', keywords=keywords):\n",
    "    \n",
    "    freq_matrix = df['tokens'].progress_apply(count_keywords, keywords=keywords)\n",
    "    freq_df = pd.DataFrame.from_records(freq_matrix, columns=keywords)\n",
    "    freq_df[by] = df[by] # copy the grouping column(s)\n",
    "    \n",
    "    return freq_df.groupby(by=by).sum().sort_values(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:43.253947Z",
     "start_time": "2020-06-24T20:35:42.065475Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "freq_df = count_keywords_by(df, by='year', keywords=keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:43.285398Z",
     "start_time": "2020-06-24T20:35:43.256423Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:43.329131Z",
     "start_time": "2020-06-24T20:35:43.287961Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:43.379391Z",
     "start_time": "2020-06-24T20:35:43.332194Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:43.808780Z",
     "start_time": "2020-06-24T20:35:43.382668Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### ax = \n",
    "freq_df.plot(kind='line', figsize=(8, 3))\n",
    "###legend = ax.get_legend()\n",
    "###legend.set_bbox_to_anchor((1, 1)) ###\n",
    "###legend.set_title('Keywords')\n",
    "###ax.set_xlabel('Year')\n",
    "### img_width: 80%\n",
    "### Figure fig-freq-by-year: Frequencies of selected words per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:44.314197Z",
     "start_time": "2020-06-24T20:35:43.811952Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(23) ###\n",
    "# analyzing mentions of 'climate' before 1980\n",
    "kwic(df.query('year < 1980')['text'], 'climate', window=35, print_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating Frequency Heat Maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:35:48.691204Z",
     "start_time": "2020-06-24T20:35:44.317898Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keywords = ['terrorism', 'terrorist', 'nuclear', 'war', 'oil',\n",
    "            'syria', 'syrian', 'refugees', 'migration', 'peacekeeping', \n",
    "            'humanitarian', 'climate', 'change', 'sustainable', 'sdgs']  \n",
    "\n",
    "freq_df = count_keywords_by(df, by='year', keywords=keywords)\n",
    "\n",
    "# compute relative frequencies based on total number of tokens per year\n",
    "freq_df = freq_df.div(df.groupby('year')['no_tokens'].sum(), axis=0)\n",
    "# apply square root as sublinear filter for better contrast\n",
    "freq_df = freq_df.apply(np.sqrt)\n",
    "\n",
    "plt.figure(figsize=(10, 3)) ###\n",
    "sns.set(font_scale=1) ###\n",
    "sns.heatmap(data=freq_df.T, \n",
    "            xticklabels=True, yticklabels=True, cbar=False, cmap=\"Reds\")\n",
    "sns.set(font_scale=1) ###\n",
    "### Figure fig-heatmap: Word frequencies over time as heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Closing Remarks\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281.563px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
